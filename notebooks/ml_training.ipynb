{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0fec23",
   "metadata": {},
   "source": [
    "# ML Training Notebook\n",
    "\n",
    "This notebook demonstrates ML model training for runtime prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ac23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic training data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "data = {\n",
    "    'partition_count': np.random.randint(10, 500, n_samples),\n",
    "    'data_size_gb': np.random.uniform(1, 100, n_samples),\n",
    "    'executor_cores': np.random.choice([4, 8, 16], n_samples),\n",
    "    'executor_memory_gb': np.random.choice([4, 8, 16, 32], n_samples),\n",
    "}\n",
    "\n",
    "# Create target: runtime (synthetic)\n",
    "data['runtime_ms'] = (\n",
    "    data['partition_count'] * 10 +\n",
    "    data['data_size_gb'] * 100 +\n",
    "    data['executor_cores'] * 50 +\n",
    "    np.random.normal(0, 500, n_samples)\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd47c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df[['partition_count', 'data_size_gb', 'executor_cores', 'executor_memory_gb']]\n",
    "y = df['runtime_ms']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c61287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Evaluation:\")\n",
    "print(f\"RMSE: {rmse:.2f} ms\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_names = ['partition_count', 'data_size_gb', 'executor_cores', 'executor_memory_gb']\n",
    "coefficients = model.coef_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': np.abs(coefficients)\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1023c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Runtime (ms)')\n",
    "axes[0].set_ylabel('Predicted Runtime (ms)')\n",
    "axes[0].set_title('Actual vs Predicted Runtime')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Predicted Runtime (ms)')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a20c26",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "This linear regression model successfully predicts Spark job runtime based on key features:\n",
    "- Partition count\n",
    "- Data size\n",
    "- Executor configuration\n",
    "\n",
    "The model can be saved and deployed for real-time predictions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
